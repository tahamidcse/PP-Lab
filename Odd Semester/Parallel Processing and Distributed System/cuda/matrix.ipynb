{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMILE+5AWJnPqyUOCTLM6E6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1769497215973,"user_tz":-360,"elapsed":24,"user":{"displayName":"Md.Al-Amin Babu","userId":"16636287286245449342"}},"outputId":"38f14d80-fe0e-43cf-ae7f-e73f482470ab","id":"7I4rzFCHL7Mp"},"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting matrix.cu\n"]}],"source":["%%writefile matrix.cu\n","#include <iostream>\n","#include <cuda_runtime.h>\n","\n","using namespace std;\n","\n","__global__ void matrixMul(float *A, float *B, float *R, int M, int N, int P, int batchOffset) {\n","  int k = threadIdx.x + batchOffset;\n","  float *a = A + k * M * N;\n","  float *b = B + k * N * P;\n","  float *r = R + k * M * P;\n","for(int outer = 0; outer < 100; outer++) {\n","  for(int i = 0; i < M; i++) {\n","    for(int l = 0; l < P; l++) {\n","      r[i * P + l] = 0.0f; // explicitly set to 0\n","      for(int j = 0; j < N; j++) {\n","        r[i * P + l] += a[i * N + j] * b[j * P + l];\n","      }\n","    }\n","  }\n","}\n","}\n","\n","// print the first matrix only\n","void printMatrix(float *A, int M, int N) {\n","  for(int i = 0; i < M; i++) {\n","    for(int j = 0; j < N; j++) {\n","      printf(\"%.0f \", A[i * N + j]);\n","    }\n","    cout<<endl;\n","  }\n","}\n","\n","int main(int argc, char* argv[]) {\n","  int threads = atoi(argv[1]);\n","  int K = atoi(argv[2]);\n","  int M = atoi(argv[3]);\n","  int N = atoi(argv[4]);\n","  int P = atoi(argv[5]);\n","\n","  //int K = 2, M = 2, N = 2, P = 2;\n","\n","  int size_of_a = K * M * N;\n","  int size_of_b = K * N * P;\n","  int size_of_r = K * M * P;\n","\n","  float *h_A = (float*)malloc(size_of_a * sizeof(float));\n","  float *h_B = (float*)malloc(size_of_b * sizeof(float));\n","  float *h_R = (float*)malloc(size_of_r * sizeof(float));\n","\n","  for(int i = 0; i < size_of_a; i++) {\n","    h_A[i] = rand() % 10;\n","  }\n","  for(int i = 0; i < size_of_b; i++) {\n","    h_B[i] = rand() % 10;\n","  }\n","  float *d_A;\n","  cudaMalloc(&d_A, size_of_a * sizeof(float));\n","  cudaMemcpy(d_A, h_A, size_of_a * sizeof(float), cudaMemcpyHostToDevice);\n","\n","  float *d_B;\n","  cudaMalloc(&d_B, size_of_b * sizeof(float));\n","  cudaMemcpy(d_B, h_B, size_of_b * sizeof(float), cudaMemcpyHostToDevice);\n","\n","  float *d_R;\n","  cudaMalloc(&d_R, size_of_r * sizeof(float));\n","  cudaMemset(d_R, 0, size_of_r * sizeof(float));\n","\n","  int remainingMatrices = K;\n","  int batchOffset = 0;\n","\n","  while(remainingMatrices > 0) {\n","    int currentBatchSize = min(remainingMatrices, threads);\n","    matrixMul<<<1, currentBatchSize>>>(d_A, d_B, d_R, M, N, P, batchOffset);\n","    cudaDeviceSynchronize();\n","    remainingMatrices -= currentBatchSize;\n","    batchOffset += currentBatchSize;\n","  }\n","\n","  cudaMemcpy(h_R, d_R, size_of_r * sizeof(float), cudaMemcpyDeviceToHost);\n","\n","  cout<<\"Matrix A[0]:\"<<endl;\n","  printMatrix(h_A, M, N);\n","  cout<<\"Matrix B[0]:\"<<endl;\n","  printMatrix(h_B, N, P);\n","  cout<<\"Matrix R[0]:\"<<endl;\n","  printMatrix(h_R, M, P);\n","  cudaFree(d_A);\n","  cudaFree(d_B);\n","  cudaFree(d_R);\n","  free(h_A);\n","  free(h_B);\n","  free(h_R);\n","  return 0;\n","}"]},{"cell_type":"code","source":["!nvcc -arch=sm_75 matrix.cu -o matrix"],"metadata":{"id":"m1VRxJnrM-Ru"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!time ./matrix 400 2200 40 40 40 > output.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EBE_ynfoQRzK","executionInfo":{"status":"ok","timestamp":1769497649607,"user_tz":-360,"elapsed":42795,"user":{"displayName":"Md.Al-Amin Babu","userId":"16636287286245449342"}},"outputId":"f0bb0e88-9f1a-460c-9355-f824d21f87d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","real\t0m42.660s\n","user\t0m42.362s\n","sys\t0m0.142s\n"]}]},{"cell_type":"code","source":["!time ./matrix 100 2200 40 40 40 > output.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dyg8GIgrQ3z8","executionInfo":{"status":"ok","timestamp":1769497500845,"user_tz":-360,"elapsed":41159,"user":{"displayName":"Md.Al-Amin Babu","userId":"16636287286245449342"}},"outputId":"e875a5ad-7671-47cb-f353-f01806c35c10"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","real\t0m41.054s\n","user\t0m40.714s\n","sys\t0m0.156s\n"]}]},{"cell_type":"code","source":["%%writefile phonebook_search.cpp\n","// I want to store the output in ascending order. How can I do it\n","!nvcc matrix.cu -o matrix\n","\n"],"metadata":{"id":"gya6XCW7vhZu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1769496583320,"user_tz":-360,"elapsed":9,"user":{"displayName":"Md.Al-Amin Babu","userId":"16636287286245449342"}},"outputId":"35040caa-70a0-4472-cf02-3f01cc708d71"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting phonebook_search.cpp\n"]}]},{"cell_type":"code","source":["!./matrix 4 2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XNZoFruXOBqv","executionInfo":{"status":"ok","timestamp":1769496651211,"user_tz":-360,"elapsed":17,"user":{"displayName":"Md.Al-Amin Babu","userId":"16636287286245449342"}},"outputId":"d9c58c0d-baf9-43e4-d526-3400c8cc672a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: ./matrix: No such file or directory\n"]}]}]}